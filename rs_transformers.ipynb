{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mempirical_distribution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ECDF\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]:\n",
    "\n",
    "\n",
    "dataset_path = Path('ml-1m')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]:\n",
    "\n",
    "\n",
    "users = pd.read_csv(\n",
    "    dataset_path/\"users.dat\",\n",
    "    sep=\"::\",\n",
    "    names=[\"user_id\", \"sex\", \"age_group\", \"occupation\", \"zip_code\"],\n",
    "    encoding='latin-1',\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    dataset_path/\"ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    names=[\"user_id\", \"movie_id\", \"rating\", \"unix_timestamp\"],\n",
    "    encoding='latin-1',\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "movies = pd.read_csv(\n",
    "    dataset_path/\"movies.dat\", sep=\"::\", names=[\"movie_id\", \"title\", \"genres\"],\n",
    "    encoding='latin-1',\n",
    "    engine='python'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]:\n",
    "\n",
    "\n",
    "ratings_df = pd.merge(ratings, movies)[['user_id', 'title', 'rating', 'unix_timestamp']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[5]:\n",
    "\n",
    "\n",
    "ratings_df[\"user_id\"] = ratings_df[\"user_id\"].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]:\n",
    "\n",
    "\n",
    "ratings_per_user = ratings_df.groupby('user_id').rating.count()\n",
    "ratings_per_item = ratings_df.groupby('title').rating.count()\n",
    "\n",
    "print(f\"Total No. of users: {len(ratings_df.user_id.unique())}\")\n",
    "print(f\"Total No. of items: {len(ratings_df.title.unique())}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Max observed rating: {ratings_df.rating.max()}\")\n",
    "print(f\"Min observed rating: {ratings_df.rating.min()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Max no. of user ratings: {ratings_per_user.max()}\")\n",
    "print(f\"Min no. of user ratings: {ratings_per_user.min()}\")\n",
    "print(f\"Median no. of ratings per user: {ratings_per_user.median()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Max no. of item ratings: {ratings_per_item.max()}\")\n",
    "print(f\"Min no. of item ratings: {ratings_per_item.min()}\")\n",
    "print(f\"Median no. of ratings per item: {ratings_per_item.median()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "\n",
    "def get_last_n_ratings_by_user(\n",
    "    df, n, min_ratings_per_user=1, user_colname=\"user_id\", timestamp_colname=\"unix_timestamp\"\n",
    "):\n",
    "    return (\n",
    "        df.groupby(user_colname)\n",
    "        .filter(lambda x: len(x) >= min_ratings_per_user)\n",
    "        .sort_values(timestamp_colname)\n",
    "        .groupby(user_colname)\n",
    "        .tail(n)\n",
    "        .sort_values(user_colname)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[8]:\n",
    "\n",
    "\n",
    "get_last_n_ratings_by_user(ratings_df, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[9]:\n",
    "\n",
    "\n",
    "def mark_last_n_ratings_as_validation_set(\n",
    "    df, n, min_ratings=1, user_colname=\"user_id\", timestamp_colname=\"unix_timestamp\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Mark the chronologically last n ratings as the validation set.\n",
    "    This is done by adding the additional 'is_valid' column to the df.\n",
    "    :param df: a DataFrame containing user item ratings\n",
    "    :param n: the number of ratings to include in the validation set\n",
    "    :param min_ratings: only include users with more than this many ratings\n",
    "    :param user_id_colname: the name of the column containing user ids\n",
    "    :param timestamp_colname: the name of the column containing the imestamps\n",
    "    :return: the same df with the additional 'is_valid' column added\n",
    "    \"\"\"\n",
    "    df[\"is_valid\"] = False\n",
    "    df.loc[\n",
    "        get_last_n_ratings_by_user(\n",
    "            df,\n",
    "            n,\n",
    "            min_ratings,\n",
    "            user_colname=user_colname,\n",
    "            timestamp_colname=timestamp_colname,\n",
    "        ).index,\n",
    "        \"is_valid\",\n",
    "    ] = True\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[10]:\n",
    "\n",
    "\n",
    "mark_last_n_ratings_as_validation_set(ratings_df, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[11]:\n",
    "\n",
    "\n",
    "train_df = ratings_df[ratings_df.is_valid==False]\n",
    "valid_df = ratings_df[ratings_df.is_valid==True]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[12]:\n",
    "\n",
    "\n",
    "len(valid_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[47]:\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[48]:\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[49]:\n",
    "\n",
    "\n",
    "users['sex_encoded'] = le.fit_transform(users.sex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[50]:\n",
    "\n",
    "\n",
    "users['age_group_encoded'] = le.fit_transform(users.age_group)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[51]:\n",
    "\n",
    "\n",
    "users[\"user_id\"] = users[\"user_id\"].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[52]:\n",
    "\n",
    "\n",
    "seq_with_user_features = pd.merge(seq_df, users)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[53]:\n",
    "\n",
    "\n",
    "train_df = seq_with_user_features[seq_with_user_features.is_valid == False]\n",
    "valid_df = seq_with_user_features[seq_with_user_features.is_valid == True]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[54]:\n",
    "\n",
    "\n",
    "class MovieSequenceDataset(Dataset):\n",
    "    def __init__(self, df, movie_lookup, user_lookup):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.movie_lookup = movie_lookup\n",
    "        self.user_lookup = user_lookup\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.iloc[index]\n",
    "        user_id = self.user_lookup[str(data.user_id)]\n",
    "        movie_ids = torch.tensor([self.movie_lookup[title] for title in data.title])\n",
    "\n",
    "        previous_ratings = torch.tensor(\n",
    "            [rating if rating != \"[PAD]\" else 0 for rating in data.previous_ratings]\n",
    "        )\n",
    "\n",
    "        attention_mask = torch.tensor(data.pad_mask)\n",
    "        target_rating = data.target_rating\n",
    "        encoded_features = {\n",
    "            \"user_id\": user_id,\n",
    "            \"movie_ids\": movie_ids,\n",
    "            \"ratings\": previous_ratings,\n",
    "            \"age_group\": data[\"age_group_encoded\"],\n",
    "            \"sex\": data[\"sex_encoded\"],\n",
    "            \"occupation\": data[\"occupation\"],\n",
    "        }\n",
    "\n",
    "        return (encoded_features, attention_mask), torch.tensor(\n",
    "            target_rating, dtype=torch.float32\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[55]:\n",
    "\n",
    "\n",
    "train_dataset = MovieSequenceDataset(train_df, movie_lookup, user_lookup)\n",
    "valid_dataset = MovieSequenceDataset(valid_df, movie_lookup, user_lookup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[56]:\n",
    "\n",
    "\n",
    "class BstTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        movies_num_unique,\n",
    "        users_num_unique,\n",
    "        sequence_length=10,\n",
    "        embedding_size=120,\n",
    "        num_transformer_layers=1,\n",
    "        ratings_range=(0.5, 5.5),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y_range = ratings_range\n",
    "        self.movies_embeddings = nn.Embedding(\n",
    "            movies_num_unique + 1, embedding_size, padding_idx=0\n",
    "        )\n",
    "        self.user_embeddings = nn.Embedding(users_num_unique + 1, embedding_size)\n",
    "        self.ratings_embeddings = nn.Embedding(6, embedding_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(sequence_length, embedding_size)\n",
    "\n",
    "        self.sex_embeddings = nn.Embedding(\n",
    "            3,\n",
    "            2,\n",
    "        )\n",
    "        self.occupation_embeddings = nn.Embedding(\n",
    "            22,\n",
    "            11,\n",
    "        )\n",
    "        self.age_group_embeddings = nn.Embedding(\n",
    "            8,\n",
    "            4,\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=nn.TransformerEncoderLayer(\n",
    "                d_model=embedding_size,\n",
    "                nhead=12,\n",
    "                dropout=0.1,\n",
    "                batch_first=True,\n",
    "                activation=\"gelu\",\n",
    "            ),\n",
    "            num_layers=num_transformer_layers,\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                embedding_size + (embedding_size * sequence_length) + 4 + 11 + 2,\n",
    "                1024,\n",
    "            ),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features, mask = inputs\n",
    "\n",
    "        user_id = self.user_embeddings(features[\"user_id\"])\n",
    "\n",
    "        age_group = self.age_group_embeddings(features[\"age_group\"])\n",
    "        sex = self.sex_embeddings(features[\"sex\"])\n",
    "        occupation = self.occupation_embeddings(features[\"occupation\"])\n",
    "\n",
    "        user_features = user_features = torch.cat(\n",
    "            (user_id, sex, age_group, occupation), 1\n",
    "        )\n",
    "\n",
    "        movie_history = features[\"movie_ids\"][:, :-1]\n",
    "        target_movie = features[\"movie_ids\"][:, -1]\n",
    "\n",
    "        ratings = self.ratings_embeddings(features[\"ratings\"])\n",
    "\n",
    "        encoded_movies = self.movies_embeddings(movie_history)\n",
    "        encoded_target_movie = self.movies_embeddings(target_movie)\n",
    "\n",
    "        positions = torch.arange(\n",
    "            0,\n",
    "            self.sequence_length - 1,\n",
    "            1,\n",
    "            dtype=int,\n",
    "            device=features[\"movie_ids\"].device,\n",
    "        )\n",
    "        positions = self.position_embeddings(positions)\n",
    "\n",
    "        encoded_sequence_movies_with_position_and_rating = (\n",
    "            encoded_movies + ratings + positions\n",
    "        )\n",
    "        encoded_target_movie = encoded_target_movie.unsqueeze(1)\n",
    "\n",
    "        transformer_features = torch.cat(\n",
    "            (encoded_sequence_movies_with_position_and_rating, encoded_target_movie),\n",
    "            dim=1,\n",
    "        )\n",
    "        transformer_output = self.encoder(\n",
    "            transformer_features, src_key_padding_mask=mask\n",
    "        )\n",
    "        transformer_output = torch.flatten(transformer_output, start_dim=1)\n",
    "\n",
    "        combined_output = torch.cat((transformer_output, user_features), dim=1)\n",
    "\n",
    "        rating = self.linear(combined_output)\n",
    "        rating = rating.squeeze()\n",
    "        if self.y_range is None:\n",
    "            return rating\n",
    "        else:\n",
    "            return rating * (self.y_range[1] - self.y_range[0]) + self.y_range[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[57]:\n",
    "\n",
    "\n",
    "notebook_launcher(train_seq_model, num_processes=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
